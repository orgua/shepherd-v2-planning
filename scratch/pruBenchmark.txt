PRU0	PRU1	Changes
161620	131324	original code
161440	131228	cgt231, pssp540
161248	130998	cgt231, pssp570
161620	131324  cgt233, pssp570
116424	108636	-O4 baseline
162116	131824  char to fixed
162632  131948  (unsigned) int to fixed
162052	131824	-O2 and revert last (int to fixed)
162244 	129348	-O3
116140	108444  -O4
161564	131364	-O2 revert fixed width types
161352	131188	pssp570g
162416 	131780  switch to fixed width, for real this time
162532	131408  cleanup type-system and constness (lib+pru1)
116032	107892	-O4 (only to check results)
114920			avoid global vars
114892			ringbuffer opt
114100			sampling and virtcap optimized, partly
114044			main is cleaner
114056	108232	cleanup printf & rpmsg
100844	95716	no debug, char = unsigned
99896	94748	?? original pssp?
99916	91368	some days later (01.08 or even before seemed fine)
108020	94292	wtf? pru0 increase is strange (were undeleted refactor-fragments)
101568  91456   cleaner trigger system for pru0, rpmsg-replacement for pru1
102236  92604   feb21, added mem_messaging and improved trigger system
78176   65948   remove printf and rpmsg
75916   61816   cleaned up resource table
76032   60964   further restructuring (2021-05)
77744   61244   still ufloat (2021-06-04)
85080   63740   bigJump 2022-07-29
85304   64276   bigJump 2023-10-07

<<<PRU1>>>
Benchmark debug-pin around gpio-read from pru1 - state was offline :(
	legacy	 -> 1.5 .. 2.9 MHz, on 60/80ns, lowest freq. estimated ~ 160 kHz
	new code -> 2.4 .. 5.5 MHz, on 40/60ns (general speed improvements)
	newer code -> relatively stable 4.03 MHz (uncorrected meas via gpio-trigger), min: 602 kHz, max: 4.55 MHz (rpmsg-replacement)
    after Sync-kernel-Update -> min-frequency should now be a bit over 1 MHz
Benchmark, same premise, for GPIO with normal routine / forced writing
	~1490 ns / ~360 ns	(base) new code, sometimes 620 ns for normal routine
	~720 ns / ~100 ns	reduce reads to far-ram to one
	~80 ns for checking events
Benchmark, code after gpio-read
	140ns	regular
	~360ns	regular on adc-trigger
	80 ns	iep-optimization
	300 ns 	adc-trigger
	5500 ns ?? buffer exchange?
->	2.5 to 5.5 MHz / 180 ns on normal Operation (with Pin-DBG on, without 170 ns / 5.9 MHz)
Event1 takes about 200 ns, 10 Hz apart
- seems to be down to 120 after cleanup / sync code moved to kernel
- 160 ns after also sending sync_request right away
    - currently scheduled 105 us before timer-wrap, kernel answers 15 us after :)
Event2 takes about 250 ns, 30 us after Event1
- 360 ns after sync code moved to kernel, some more variables to write
Event3(expensive part):
- 540 ns for check control reply, ~ 16us after Event2, repeated with 100 kHz, finished after <=306 us after E2
- 4550 ns for complete part (control reply arrived)
- 5200 ns for unoptimized complete part, 3.7 us alone for check_control_reply
- 40 ns for check ctrl reply (rpms-replacement)
- 1140 ns for for complete part (control reply arrived) (rpmsg-replacement)
Event3 NEW - complete routine (with setting cmp-timer)
- 140 ns -> for setting timer and checking inbox
- 460 ns -> incl receiving a msg -> expensive code is now in kernel
SysGpio
- 220 ns for check and compare,
<<new mem-msg-sys + opt - 2021-05>>
120 ns GPIO-Check (min 100 ns) without pin-change
 60 ns Offtime to check the others
        -> 15 ns for benchmark-pin-setting (asm-count)
        -> 150 ns to 170 ns shortest loop
280 ns Offtime for CMP0
460 ns Offtime MAX (1s search-window)
        -> mean 5.7 MHz (logicA)
        -> min  1.7 MHz (120 + 460 - 15)ns
        -> max  6.8 MHz (100 + 60 - 15)ns
740 ns GPIO-Check with PinChange (min 600 ns, minFullBuff 320 ns, max?? 5180 ns)
        -> 20 ns for benchmark-pin-setting (asm-count)
        -> mean 2.2 MHz (logicA)
        -> min  840 kHz (740 + 460 - 20)ns
    -> now a bit slower due to PwrGood-Code

<<<PRU0>>>
560 ns 	handle_rpmsg(), sometimes (before long E3) 1020 ns (without receiving)
4340 ns sampling() / harvesting & load
6860 ns sampling() / emulation
4220 ns sampling() / vcap
2740 ns handling block end -> pru1-blocking part was reduced to 460 ns
550-630 ns for ADC reading in HW rev 2 (instead of ~2060)
450-550 ns for ADC reading (further improvement)
720 ns for DAC write (instead of 980 ns)
1250 ns sampling() / harvesting (2 ADC, store)
2000 ns sampling() / harvesting (2x ADC, store, calc, 1x DAC)
xxxx ns sampling() / virtualSource, 21/36 us, including 2x ADC, 1x DAC (~2 us) -> prototype
    -> 8 us makes ~ 1600 instructions
<<new mem-msg-sys + opt - 2021-05>>
80 ns   time between sampling and checking for msgs
40 ns   checking for msg (inbox empty)
800 ns  buffer-swap
    400 ns prepare buffer
    200 ns mutex-part / gpio-swap (Mutex part was 460 ns before, 2700 ns before that)
    200 ns send full buffer
260 ns  check and receive msg


Sampling-VSource-Performance
- Baseline (21.01.20)
    - 17000 ns init vsource -> 5cmd 1900ns, 5cmd 1220ns, 5cmd 1440ns, 2cmd 660 ns, 7cmd 11740ns
    -   600 ns enter sampling, choose emulation, get 2x u32 out of ram
    -   500 ns ADC reading
    -  1500 ns calculate P_in
    -  3300 ns calculate P_out
    -  3240 ns calculate P_sum
    -    60 ns handle events
    -   750 ns DAC writing
- Init
    - 17'000 ns init vsource -> 5cmd 1900ns, 5cmd 1220ns, 5cmd 1440ns, 2cmd 660 ns, 7cmd 11740ns
    - 10'940 ns init vsource -> 5cmd   80ns, 5cmd  320ns, 5cmd  960ns, 2cmd 320 ns, 7cmd 10260ns
    - 10'940 ns init vsource -> argcopy 80ns, boost 1260ns, buck 340ns, dV-sq 4300ns, sqrt 5960ns
    -  1'740 ns init vsource -> argcopy 80ns, boost 1260ns, buck 340ns (outsource rest to py)
    -  3'320 ns copy vs_cfg completely
- Sampling
    - 1500 ns P_in, 3300 ns P_out, 3240 ns P_sum -> baseline
    - 1240 ns P_in, 5540 ns P_out, 3240 ns P_sum -> first improvement
    - 1380 ns P_in, 4340 ns P_out, 2960 ns P_sum -> second improvements
    - 1440 ns P_in, 4340 ns P_out, 3240 ns P_sum -> ufloat uses num1 as result, optimal fn (except equalize & mult)
    - 1440 ns P_in, 2540 ns P_out, 1940 ns P_sum, 540 ns events -> optimize ufloat equalize & mult, LUT-FNs
    - sum = 6500 ns
